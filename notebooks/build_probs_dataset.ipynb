{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb6b0a9",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "031a2430-7ba4-431f-8e42-e31baf9ce991",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas==1.3.4 in /opt/conda/lib/python3.8/site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.4) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.4) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.3.4) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers==4.12.5 in /opt/conda/lib/python3.8/site-packages (4.12.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (2021.10.8)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (3.3.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.0.46)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (1.21.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.7.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.12.5) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.12.5) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (2.0.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (8.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets==1.15.1 in /opt/conda/lib/python3.8/site-packages (1.15.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (21.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (2.26.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (1.21.2)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (0.70.13)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (4.62.3)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (8.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (3.8.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (3.0.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (0.3.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (0.7.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (2022.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.15.1) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.15.1) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.15.1) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets==1.15.1) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (1.26.7)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (21.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==1.15.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==1.15.1) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets==1.15.1) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (7.7.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (1.1.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (58.2.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.0.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.11.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==1.3.4\n",
    "!pip install transformers==4.12.5\n",
    "!pip install datasets==1.15.1\n",
    "#!pip install datasets\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68151271",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "db736e14-03fb-4438-938d-c705d6786666",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import ClassLabel\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5722ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c305c8a7",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "37286c02-6bf4-41f5-ab70-51515a054e7b",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8697c80d",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "0c699094-439f-4dda-85a9-815e7948540c",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/notebooks/Data/bert_sequence_classification'\n",
    "DATA_FILE = '/notebooks/ICANN/Datasets/dataset_persuasive_essays_icann.pt'\n",
    "RESULTS_FOLDER = '/notebooks/cascade_bert/saved_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0710b6",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "35aada91-232a-421e-a28f-94b359c6d65d",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7cca355",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "dc52e71e-65fa-4946-acdf-e4fffe9d0f79",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbaa9d2",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d352c1cd-abff-4b1e-b5e2-611288e4fddb",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8035b28e",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "013a6d64-65e7-4189-a468-40ecfd8a6736",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9963a749",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "626737f9-ff56-4992-b72b-60750375e455",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset = torch.load(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bd3426b",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "4fbfcc7b-55fb-456e-ab02-2ae975803046",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['split', 'text', 'labels', 'sentence', 'topic_and_full_sentence', 'topic_full_sentence_stuctural_fts', 'topic_full_sentence_structural_fts_combined', 'feature_tensor'],\n",
       "        num_rows: 4709\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['split', 'text', 'labels', 'sentence', 'topic_and_full_sentence', 'topic_full_sentence_stuctural_fts', 'topic_full_sentence_structural_fts_combined', 'feature_tensor'],\n",
       "        num_rows: 1258\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6dc66e0",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "57c21a2e-83cd-4f4b-a19a-0bae29eb4794",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Topic: Some young adults want independence from their parents quickly. Sentence: There will not be such worries when young adults live in their own home, because parents will take care for them. Structural features: Two. No. No. No. No.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['topic_full_sentence_structural_fts_combined'][230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "215f1813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54859a50fd7449f6b31b5f0d59c7daf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['train'] = dataset['train'].flatten_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b788ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4421f137a154e17b90e7c0dccd664e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['test'] = dataset['test'].flatten_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "949a2394",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "492e0415-2634-47bb-88bf-665c130d032c",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9543f88a",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 9,
     "id": "ba2c9132-d013-4b26-be96-146cf024a45e",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "label_names = ['Claim', 'Premise', 'MajorClaim']\n",
    "label_nb = len(label_names)\n",
    "labels = ClassLabel(num_classes=label_nb, names=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e55331a",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 10,
     "id": "2f1ce51b-18bc-40db-983f-3434b8651e45",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(num_classes=3, names=['Claim', 'Premise', 'MajorClaim'], names_file=None, id=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b82113b2",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 11,
     "id": "5438b78c-249c-48ac-98e8-a87a2cc0c86d",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    tokens = tokenizer(batch['topic_full_sentence_structural_fts_combined'], truncation=True, padding=True, max_length=512)\n",
    "    tokens['labels'] = labels.str2int(batch['labels'])\n",
    "    return tokens\n",
    "\n",
    "# this is just the text. if the results are nice, check transfer with text + topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3cb78c2",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 12,
     "id": "cb8d8c9a-7539-4d02-9dc5-98bade787549",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize at 0x7f2d32e4c310> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4f79c9a9d34eff92877b1396a84d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41201c1299a644b7a8d1a70b98d40e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e84780b",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 13,
     "id": "84abf830-f842-4e91-8d5c-7fcd9ea2942e",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d10dec6",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 14,
     "id": "c7d70e98-c2e0-4055-9d52-74c67c199c72",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'feature_tensor', 'input_ids', 'labels', 'sentence', 'split', 'text', 'token_type_ids', 'topic_and_full_sentence', 'topic_full_sentence_structural_fts_combined', 'topic_full_sentence_stuctural_fts'],\n",
       "        num_rows: 4709\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'feature_tensor', 'input_ids', 'labels', 'sentence', 'split', 'text', 'token_type_ids', 'topic_and_full_sentence', 'topic_full_sentence_structural_fts_combined', 'topic_full_sentence_stuctural_fts'],\n",
       "        num_rows: 1258\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c6ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cb462e9",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 15,
     "id": "e825c71a-23f8-4794-b114-729819def9ab",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']#.shuffle(seed=42)\n",
    "test_dataset = dataset['test']#.shuffle(seed=42)\n",
    "\n",
    "# train_val_datasets = dataset['train'].train_test_split(train_size=0.8)\n",
    "# train_dataset = train_val_datasets['train']\n",
    "# val_dataset = train_val_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2780163",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 16,
     "id": "e13433b1-343d-417d-bfbd-8bacb4c57d23",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset_d = {}\n",
    "dataset_d['train'] = train_dataset\n",
    "dataset_d['test'] = test_dataset\n",
    "# dataset_d['val'] = val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "046f6c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'feature_tensor', 'input_ids', 'labels', 'sentence', 'split', 'text', 'token_type_ids', 'topic_and_full_sentence', 'topic_full_sentence_structural_fts_combined', 'topic_full_sentence_stuctural_fts'],\n",
       "    num_rows: 1258\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7c08bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4709, 1258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d74b2a7",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 17,
     "id": "a298a871-1a0d-4ed8-9a1c-1ed3795f1d74",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] topic : what's more important : hard work or luck? sentence : it is not for which ronaldo is more fortune than me. structural features : two. no. no. no. no. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset['train'][2945]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fa185ac",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 18,
     "id": "aa1384b3-bd47-41a3-86b1-9cf814d47cdf",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(dataset_d['train']['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41a42af8",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 20,
     "id": "406ad783-a570-4c26-8aa6-243e866b6fbf",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TEST'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(dataset_d['test']['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a4894d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a79b5752",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05c24b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #load model\n",
    "model_file = os.path.join(\"/notebooks/cascade_bert/saved_models\", 'best-model-probs')\n",
    "# model_file = os.path.join(RESULTS_FOLDER, 'checkpoint-1500')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_file, num_labels=3)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4a140d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, data_collator=DataCollatorWithPadding(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daa86bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: topic_and_full_sentence, split, sentence, topic_full_sentence_stuctural_fts, topic_full_sentence_structural_fts_combined, feature_tensor, text.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1258\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='747' max='158' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [158/158 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_raw_preds, test_labels, _ = trainer.predict(test_dataset)\n",
    "test_preds = np.argmax(test_raw_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55250d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69       301\n",
      "           1       0.93      0.88      0.90       805\n",
      "           2       0.79      0.92      0.85       152\n",
      "\n",
      "    accuracy                           0.84      1258\n",
      "   macro avg       0.80      0.84      0.82      1258\n",
      "weighted avg       0.85      0.84      0.85      1258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# target_name = labels.int2str([0,1,2])\n",
    "print(classification_report(test_labels, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4d6892e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: topic_and_full_sentence, split, sentence, topic_full_sentence_stuctural_fts, topic_full_sentence_structural_fts_combined, feature_tensor, text.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 4709\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "train_raw_preds, train_labels, _ = trainer.predict(train_dataset)\n",
    "train_preds = np.argmax(train_raw_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "227d05dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.66      1173\n",
      "           1       0.92      0.87      0.89      2957\n",
      "           2       0.77      0.90      0.83       579\n",
      "\n",
      "    accuracy                           0.83      4709\n",
      "   macro avg       0.78      0.82      0.80      4709\n",
      "weighted avg       0.83      0.83      0.83      4709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# target_name = labels.int2str([0,1,2])\n",
    "print(classification_report(train_labels, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90353ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the correct softmax thing\n",
    "\n",
    "# x = torch.softmax(torch.tensor(train_raw_preds[0]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f763341d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "list(train_labels) == list(dataset['train']['labels']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ffdaaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "list(test_labels) == list(dataset['test']['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42acff6",
   "metadata": {},
   "source": [
    "### dataset work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fad0228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4709, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d351d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the correct softmax thing\n",
    "\n",
    "x = torch.softmax(torch.tensor(train_raw_preds[0]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac79e09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0393, 0.0224, 0.9383])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4015ccba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a8069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c022f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs = np.array(train_raw_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe68915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = np.array(test_raw_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e2dbb74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.82, -1.38,  2.36], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5ab2fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs = np.round(train_probs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "415a4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = np.round(test_probs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6d1c02c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38, -1.06,  0.34],\n",
       "       [-0.05, -2.19,  1.46],\n",
       "       [ 0.59,  3.03, -2.52],\n",
       "       ...,\n",
       "       [ 0.99,  2.18, -2.6 ],\n",
       "       [ 0.92,  3.2 , -2.66],\n",
       "       [-0.74, -2.08,  2.2 ]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "874ee347",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list_train = []\n",
    "\n",
    "for i in range(0, 4709, 1):\n",
    "    \n",
    "    new_list_train.append(str(train_probs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "50688a33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[-0.82 -1.38  2.36]'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "11902d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e51c271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_probs = pd.DataFrame(new_list_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6c9d4003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.82 -1.38  2.36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ 1.54  0.69 -2.34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ 0.32  3.74 -2.35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ 0.5   3.78 -2.47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ 0.81  3.53 -2.65]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>[ 0.71  3.29 -2.78]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705</th>\n",
       "      <td>[ 0.84  2.61 -2.78]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4706</th>\n",
       "      <td>[ 0.84  2.61 -2.78]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>[ 1.29  1.68 -2.75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>[-0.69 -2.19  2.19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4709 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "0     [-0.82 -1.38  2.36]\n",
       "1     [ 1.54  0.69 -2.34]\n",
       "2     [ 0.32  3.74 -2.35]\n",
       "3     [ 0.5   3.78 -2.47]\n",
       "4     [ 0.81  3.53 -2.65]\n",
       "...                   ...\n",
       "4704  [ 0.71  3.29 -2.78]\n",
       "4705  [ 0.84  2.61 -2.78]\n",
       "4706  [ 0.84  2.61 -2.78]\n",
       "4707  [ 1.29  1.68 -2.75]\n",
       "4708  [-0.69 -2.19  2.19]\n",
       "\n",
       "[4709 rows x 1 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bc89350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list_test = []\n",
    "\n",
    "for i in range(0, 1258, 1):\n",
    "    \n",
    "    new_list_test.append(str(test_probs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "49471291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[ 0.38 -1.06  0.34]',\n",
       " '[-0.05 -2.19  1.46]',\n",
       " '[ 0.59  3.03 -2.52]',\n",
       " '[ 0.09  3.73 -2.09]',\n",
       " '[-0.02  3.64 -2.  ]',\n",
       " '[ 1.45  0.05 -1.77]',\n",
       " '[ 0.56  3.38 -2.62]',\n",
       " '[-0.26  3.56 -1.69]',\n",
       " '[ 0.14  3.8  -2.19]',\n",
       " '[ 1.42  0.34 -2.  ]',\n",
       " '[-0.32 -2.34  1.73]',\n",
       " '[-0.78 -1.45  2.35]',\n",
       " '[ 1.53  0.65 -2.34]',\n",
       " '[ 0.82  3.02 -2.61]',\n",
       " '[ 1.56  0.55 -2.29]',\n",
       " '[ 0.57  3.71 -2.53]',\n",
       " '[ 0.57  3.71 -2.53]',\n",
       " '[ 1.01  2.55 -2.73]',\n",
       " '[ 1.41  0.95 -2.42]',\n",
       " '[ 0.57  3.78 -2.54]',\n",
       " '[ 1.4   0.49 -2.03]',\n",
       " '[ 0.46 -2.05  0.92]',\n",
       " '[ 0.76 -1.74  0.29]',\n",
       " '[-0.16 -2.31  1.57]',\n",
       " '[ 1.12 -0.93 -0.86]',\n",
       " '[ 1.49  0.6  -2.28]',\n",
       " '[ 0.58  3.72 -2.53]',\n",
       " '[ 0.11  3.64 -2.13]',\n",
       " '[ 1.32  0.58 -2.07]',\n",
       " '[ 0.9   3.36 -2.76]',\n",
       " '[ 1.43  0.81 -2.36]',\n",
       " '[-0.03  3.49 -2.07]',\n",
       " '[ 0.36  3.55 -2.32]',\n",
       " '[ 1.52  0.49 -2.25]',\n",
       " '[ 0.31  3.82 -2.37]',\n",
       " '[ 0.25  3.69 -2.32]',\n",
       " '[ 0.05  3.71 -2.2 ]',\n",
       " '[ 0.43  3.75 -2.52]',\n",
       " '[ 0.14  3.67 -2.25]',\n",
       " '[ 0.36  3.77 -2.44]',\n",
       " '[ 0.56  3.46 -2.44]',\n",
       " '[-0.71 -2.19  2.19]',\n",
       " '[ 1.06 -1.11 -0.45]',\n",
       " '[ 1.37  0.89 -2.36]',\n",
       " '[ 1.49  0.87 -2.44]',\n",
       " '[ 0.06 -2.23  1.43]',\n",
       " '[ 1.44  0.89 -2.37]',\n",
       " '[ 1.27  0.56 -2.02]',\n",
       " '[ 0.68  3.19 -2.69]',\n",
       " '[ 0.43  3.76 -2.41]',\n",
       " '[ 0.01  3.62 -2.06]',\n",
       " '[ 1.26  1.64 -2.71]',\n",
       " '[ 1.49  0.64 -2.27]',\n",
       " '[ 0.82  2.81 -2.8 ]',\n",
       " '[ 0.66  3.22 -2.67]',\n",
       " '[ 0.66  3.62 -2.65]',\n",
       " '[ 0.76  3.21 -2.83]',\n",
       " '[ 1.08  1.7  -2.53]',\n",
       " '[ 0.9   3.03 -2.78]',\n",
       " '[-0.75 -2.12  2.22]',\n",
       " '[ 1.48  0.79 -2.42]',\n",
       " '[ 0.9   2.15 -2.69]',\n",
       " '[ 0.58  3.36 -2.62]',\n",
       " '[ 0.58  3.36 -2.62]',\n",
       " '[ 0.73  3.52 -2.48]',\n",
       " '[ 1.11 -0.65 -0.82]',\n",
       " '[ 0.41  3.79 -2.46]',\n",
       " '[ 0.99  2.27 -2.74]',\n",
       " '[-0.07 -2.38  1.62]',\n",
       " '[ 1.46  0.76 -2.37]',\n",
       " '[ 1.2  -1.02 -0.8 ]',\n",
       " '[ 1.51  0.53 -2.21]',\n",
       " '[ 0.4   3.65 -2.32]',\n",
       " '[-0.16  3.42 -1.84]',\n",
       " '[-0.05  3.49 -2.05]',\n",
       " '[ 0.34  3.7  -2.38]',\n",
       " '[ 0.48  3.68 -2.4 ]',\n",
       " '[ 0.86  3.1  -2.79]',\n",
       " '[ 1.42  0.79 -2.35]',\n",
       " '[ 0.03  3.6  -2.  ]',\n",
       " '[ 0.03  3.6  -2.  ]',\n",
       " '[ 0.57  3.71 -2.52]',\n",
       " '[ 0.81  3.05 -2.6 ]',\n",
       " '[ 0.45 -2.05  0.92]',\n",
       " '[ 0.76 -1.62  0.22]',\n",
       " '[-0.7  -2.23  2.13]',\n",
       " '[ 1.48  0.72 -2.34]',\n",
       " '[ 0.5   3.82 -2.57]',\n",
       " '[-0.34  3.23 -1.6 ]',\n",
       " '[ 0.68  3.19 -2.8 ]',\n",
       " '[-0.01  3.7  -2.06]',\n",
       " '[-0.23  3.32 -1.74]',\n",
       " '[ 0.78  3.48 -2.63]',\n",
       " '[ 1.53  0.39 -2.15]',\n",
       " '[-0.02  3.63 -2.12]',\n",
       " '[ 0.01  3.66 -2.19]',\n",
       " '[ 0.    3.68 -2.15]',\n",
       " '[ 0.81  3.35 -2.58]',\n",
       " '[ 1.52  0.53 -2.28]',\n",
       " '[-0.26  3.35 -1.66]',\n",
       " '[ 0.35  3.73 -2.46]',\n",
       " '[-0.01  3.71 -2.14]',\n",
       " '[ 0.31  3.77 -2.39]',\n",
       " '[ 0.48  3.61 -2.36]',\n",
       " '[ 0.41 -2.06  0.98]',\n",
       " '[ 0.63 -1.85  0.59]',\n",
       " '[-0.8  -1.47  2.25]',\n",
       " '[ 1.36  1.14 -2.48]',\n",
       " '[ 0.35  3.55 -2.22]',\n",
       " '[ 1.52  0.52 -2.23]',\n",
       " '[ 0.87  2.39 -2.62]',\n",
       " '[ 0.19  3.77 -2.22]',\n",
       " '[ 0.42  3.71 -2.39]',\n",
       " '[-0.4   3.12 -1.4 ]',\n",
       " '[ 0.85  3.28 -2.43]',\n",
       " '[ 0.08 -2.24  1.4 ]',\n",
       " '[ 0.58 -1.91  0.66]',\n",
       " '[-0.78 -1.49  2.33]',\n",
       " '[ 1.47  0.51 -2.17]',\n",
       " '[ 0.32  3.66 -2.33]',\n",
       " '[ 1.52  0.47 -2.21]',\n",
       " '[ 0.33  3.79 -2.37]',\n",
       " '[ 0.53  3.49 -2.28]',\n",
       " '[ 1.42  1.   -2.48]',\n",
       " '[ 0.44  3.26 -2.21]',\n",
       " '[-0.71 -2.05  2.18]',\n",
       " '[-0.77 -1.66  2.33]',\n",
       " '[ 1.53  0.39 -2.14]',\n",
       " '[ 0.41  3.77 -2.43]',\n",
       " '[ 0.5   3.79 -2.52]',\n",
       " '[ 0.43  3.74 -2.4 ]',\n",
       " '[ 0.39  3.57 -2.25]',\n",
       " '[ 1.52  0.53 -2.27]',\n",
       " '[ 0.12  3.69 -2.2 ]',\n",
       " '[ 0.46  3.71 -2.49]',\n",
       " '[ 1.11  1.79 -2.65]',\n",
       " '[ 0.99  2.57 -2.83]',\n",
       " '[ 0.9  -1.44 -0.01]',\n",
       " '[-0.08 -2.34  1.58]',\n",
       " '[-0.8  -1.23  2.26]',\n",
       " '[ 1.45  0.78 -2.32]',\n",
       " '[ 0.81  2.84 -2.75]',\n",
       " '[ 0.81  2.84 -2.75]',\n",
       " '[ 0.36  3.77 -2.41]',\n",
       " '[ 0.98  2.13 -2.59]',\n",
       " '[ 1.51  0.65 -2.3 ]',\n",
       " '[ 0.19  3.85 -2.28]',\n",
       " '[ 0.24  3.81 -2.27]',\n",
       " '[ 0.84  2.91 -2.72]',\n",
       " '[ 1.49  0.58 -2.27]',\n",
       " '[ 0.34  3.84 -2.38]',\n",
       " '[ 0.63  3.11 -2.58]',\n",
       " '[-0.75 -2.12  2.21]',\n",
       " '[ 1.41  0.68 -2.23]',\n",
       " '[ 1.25  0.64 -2.  ]',\n",
       " '[ 1.18  1.37 -2.47]',\n",
       " '[ 0.5   3.73 -2.41]',\n",
       " '[ 0.67  3.56 -2.45]',\n",
       " '[ 1.28  1.52 -2.5 ]',\n",
       " '[ 0.87  2.57 -2.77]',\n",
       " '[ 1.28 -0.35 -1.23]',\n",
       " '[ 0.67 -1.78  0.49]',\n",
       " '[ 0.58 -1.96  0.77]',\n",
       " '[-0.77 -1.56  2.3 ]',\n",
       " '[ 1.47  0.51 -2.15]',\n",
       " '[ 0.77  2.61 -2.57]',\n",
       " '[ 1.38  0.18 -1.84]',\n",
       " '[ 1.32  1.41 -2.6 ]',\n",
       " '[ 0.9   2.37 -2.77]',\n",
       " '[ 0.18  3.73 -2.28]',\n",
       " '[ 0.29  3.77 -2.35]',\n",
       " '[ 1.02  2.36 -2.79]',\n",
       " '[ 1.46  0.82 -2.34]',\n",
       " '[ 1.02  1.94 -2.63]',\n",
       " '[ 0.47  3.68 -2.45]',\n",
       " '[ 0.65  3.44 -2.47]',\n",
       " '[ 0.73 -1.79  0.39]',\n",
       " '[ 0.95 -1.5  -0.12]',\n",
       " '[-0.81 -1.4   2.32]',\n",
       " '[ 1.53  0.45 -2.12]',\n",
       " '[ 0.16  3.8  -2.18]',\n",
       " '[ 0.2   3.74 -2.16]',\n",
       " '[ 1.39  0.04 -1.71]',\n",
       " '[ 1.53  0.58 -2.28]',\n",
       " '[ 0.6   3.26 -2.57]',\n",
       " '[-0.02  3.37 -1.9 ]',\n",
       " '[ 1.48  0.53 -2.16]',\n",
       " '[ 0.09  3.63 -2.21]',\n",
       " '[-0.35  3.12 -1.4 ]',\n",
       " '[-0.21  3.05 -1.5 ]',\n",
       " '[-0.28 -2.4   1.72]',\n",
       " '[ 0.77 -1.63  0.31]',\n",
       " '[-0.8  -1.82  2.3 ]',\n",
       " '[ 1.39  1.09 -2.49]',\n",
       " '[ 0.79  2.6  -2.66]',\n",
       " '[ 0.57  3.8  -2.56]',\n",
       " '[ 0.57  3.8  -2.56]',\n",
       " '[ 1.14  1.37 -2.39]',\n",
       " '[-0.08  3.51 -1.92]',\n",
       " '[ 1.48  0.55 -2.28]',\n",
       " '[ 0.53  3.77 -2.54]',\n",
       " '[ 0.04  3.7  -2.16]',\n",
       " '[ 0.07  3.71 -2.23]',\n",
       " '[-0.24  3.42 -1.67]',\n",
       " '[-0.38  3.18 -1.6 ]',\n",
       " '[-0.28  3.23 -1.67]',\n",
       " '[-0.49  2.93 -1.23]',\n",
       " '[-0.38  3.09 -1.45]',\n",
       " '[ 1.41  0.05 -1.76]',\n",
       " '[-0.78 -1.99  2.22]',\n",
       " '[-0.74 -1.59  2.32]',\n",
       " '[ 1.53  0.65 -2.33]',\n",
       " '[ 0.75  2.73 -2.67]',\n",
       " '[ 1.41  0.48 -2.12]',\n",
       " '[ 1.52  0.67 -2.34]',\n",
       " '[ 1.07  1.81 -2.64]',\n",
       " '[ 0.76  2.89 -2.76]',\n",
       " '[ 0.05  3.5  -2.03]',\n",
       " '[ 1.4   1.17 -2.56]',\n",
       " '[ 0.78  3.61 -2.61]',\n",
       " '[-0.74 -1.72  2.26]',\n",
       " '[-0.84 -1.26  2.3 ]',\n",
       " '[ 1.5   0.18 -1.97]',\n",
       " '[ 0.34  3.81 -2.36]',\n",
       " '[ 0.43  3.26 -2.51]',\n",
       " '[ 0.64  3.67 -2.6 ]',\n",
       " '[ 0.51  3.81 -2.55]',\n",
       " '[ 0.67  3.2  -2.73]',\n",
       " '[ 0.34  3.6  -2.24]',\n",
       " '[ 1.52  0.23 -2.03]',\n",
       " '[ 0.09  3.81 -2.22]',\n",
       " '[ 0.32  3.4  -2.21]',\n",
       " '[ 1.55  0.35 -2.14]',\n",
       " '[ 0.88  2.36 -2.6 ]',\n",
       " '[ 1.4   0.32 -1.94]',\n",
       " '[-0.77 -1.8   2.29]',\n",
       " '[ 1.29  1.41 -2.53]',\n",
       " '[ 0.65  2.79 -2.55]',\n",
       " '[ 0.13  3.79 -2.22]',\n",
       " '[ 0.61  3.75 -2.6 ]',\n",
       " '[ 0.49  3.74 -2.42]',\n",
       " '[ 1.37  1.14 -2.5 ]',\n",
       " '[ 0.02  3.67 -2.18]',\n",
       " '[ 0.49  3.71 -2.42]',\n",
       " '[ 0.55  3.4  -2.61]',\n",
       " '[ 0.48  3.68 -2.39]',\n",
       " '[ 0.42 -2.13  1.07]',\n",
       " '[ 0.54 -1.96  0.78]',\n",
       " '[ 1.43  0.97 -2.47]',\n",
       " '[ 0.05  3.7  -2.23]',\n",
       " '[ 1.06  2.07 -2.64]',\n",
       " '[ 1.53  0.17 -2.02]',\n",
       " '[ 0.13  3.69 -2.25]',\n",
       " '[ 0.49  3.55 -2.41]',\n",
       " '[ 1.53  0.46 -2.24]',\n",
       " '[ 0.08  3.68 -2.14]',\n",
       " '[ 0.43  3.55 -2.4 ]',\n",
       " '[ 0.13  3.78 -2.19]',\n",
       " '[ 0.45  3.69 -2.41]',\n",
       " '[ 0.6   3.2  -2.65]',\n",
       " '[ 0.58  3.51 -2.63]',\n",
       " '[ 0.93  2.73 -2.8 ]',\n",
       " '[-0.83 -1.55  2.33]',\n",
       " '[ 1.41  0.79 -2.26]',\n",
       " '[ 0.73  3.07 -2.74]',\n",
       " '[ 1.42  0.94 -2.41]',\n",
       " '[ 0.93  2.42 -2.77]',\n",
       " '[ 0.16  3.69 -2.2 ]',\n",
       " '[ 0.16  3.69 -2.2 ]',\n",
       " '[ 0.68  3.02 -2.69]',\n",
       " '[ 0.97  3.19 -2.64]',\n",
       " '[ 0.02 -2.3   1.55]',\n",
       " '[ 0.05 -2.25  1.5 ]',\n",
       " '[-0.75 -1.51  2.32]',\n",
       " '[ 1.42  0.7  -2.28]',\n",
       " '[ 0.58  3.66 -2.53]',\n",
       " '[ 0.24  3.7  -2.27]',\n",
       " '[-0.17  3.38 -1.74]',\n",
       " '[ 0.54  3.64 -2.52]',\n",
       " '[ 0.01  3.61 -2.16]',\n",
       " '[ 1.35  0.86 -2.3 ]',\n",
       " '[ 1.39  0.87 -2.43]',\n",
       " '[-0.07  3.62 -2.05]',\n",
       " '[-0.01  3.55 -2.13]',\n",
       " '[ 0.36  3.78 -2.41]',\n",
       " '[ 0.68  3.43 -2.71]',\n",
       " '[ 0.06  3.61 -2.05]',\n",
       " '[-0.22  3.37 -1.7 ]',\n",
       " '[-0.14  3.41 -1.89]',\n",
       " '[ 1.06  2.42 -2.8 ]',\n",
       " '[-0.72 -1.84  2.23]',\n",
       " '[-0.74 -1.32  2.28]',\n",
       " '[ 1.31  0.35 -1.69]',\n",
       " '[-0.38  3.14 -1.39]',\n",
       " '[-0.38  3.14 -1.39]',\n",
       " '[ 1.21 -0.4  -1.09]',\n",
       " '[ 1.41  0.31 -1.87]',\n",
       " '[ 0.39  3.68 -2.39]',\n",
       " '[-0.09  3.53 -1.95]',\n",
       " '[ 1.31 -0.07 -1.35]',\n",
       " '[ 1.47  0.58 -2.22]',\n",
       " '[ 0.76  2.62 -2.66]',\n",
       " '[ 0.3  3.7 -2.3]',\n",
       " '[ 0.03  3.2  -1.82]',\n",
       " '[-0.25 -2.4   1.72]',\n",
       " '[ 0.69 -1.39  0.28]',\n",
       " '[-0.18 -2.25  1.55]',\n",
       " '[-0.15 -2.4   1.68]',\n",
       " '[-0.12 -2.24  1.55]',\n",
       " '[ 1.51  0.68 -2.32]',\n",
       " '[ 0.12  3.79 -2.24]',\n",
       " '[ 0.08  3.74 -2.11]',\n",
       " '[-0.06  3.54 -1.96]',\n",
       " '[-0.05  3.57 -1.96]',\n",
       " '[ 1.46  0.51 -2.21]',\n",
       " '[ 1.42  0.86 -2.42]',\n",
       " '[ 0.37  3.77 -2.4 ]',\n",
       " '[ 1.38  0.01 -1.71]',\n",
       " '[-0.8  -1.36  2.31]',\n",
       " '[-0.76 -1.93  2.24]',\n",
       " '[ 1.5   0.48 -2.23]',\n",
       " '[ 0.39  3.85 -2.38]',\n",
       " '[ 1.3  -0.06 -1.49]',\n",
       " '[ 1.13 -0.55 -0.81]',\n",
       " '[-0.13  3.51 -1.91]',\n",
       " '[-0.31  3.29 -1.63]',\n",
       " '[-0.31  3.29 -1.63]',\n",
       " '[ 0.05  3.33 -1.89]',\n",
       " '[ 1.53  0.49 -2.2 ]',\n",
       " '[ 0.55  3.53 -2.5 ]',\n",
       " '[ 1.06  2.19 -2.7 ]',\n",
       " '[-0.79 -2.16  2.21]',\n",
       " '[-0.35 -2.43  1.81]',\n",
       " '[-0.2  -2.26  1.6 ]',\n",
       " '[ 1.5   0.69 -2.34]',\n",
       " '[ 0.76  2.83 -2.72]',\n",
       " '[ 0.76  2.83 -2.72]',\n",
       " '[ 0.78  2.91 -2.75]',\n",
       " '[ 1.07  2.34 -2.75]',\n",
       " '[ 1.52  0.6  -2.32]',\n",
       " '[ 0.5   3.72 -2.49]',\n",
       " '[ 1.35  1.28 -2.58]',\n",
       " '[ 1.45  0.63 -2.28]',\n",
       " '[ 0.48  3.7  -2.44]',\n",
       " '[ 0.37  3.71 -2.27]',\n",
       " '[ 0.37  3.71 -2.27]',\n",
       " '[ 0.73  3.01 -2.68]',\n",
       " '[ 0.3  -2.18  1.17]',\n",
       " '[ 1.16 -1.06 -0.72]',\n",
       " '[ 0.83 -1.58  0.09]',\n",
       " '[ 0.06 -2.22  1.37]',\n",
       " '[ 1.54  0.35 -2.14]',\n",
       " '[ 0.62  3.55 -2.6 ]',\n",
       " '[ 0.62  3.55 -2.6 ]',\n",
       " '[ 0.42  3.78 -2.43]',\n",
       " '[-0.12  3.52 -1.9 ]',\n",
       " '[-0.12  3.52 -1.9 ]',\n",
       " '[ 0.67  3.66 -2.62]',\n",
       " '[-0.06  3.5  -1.98]',\n",
       " '[ 0.23  3.72 -2.25]',\n",
       " '[ 0.15  3.75 -2.31]',\n",
       " '[ 0.51  3.6  -2.45]',\n",
       " '[ 1.55  0.5  -2.27]',\n",
       " '[-0.13  3.51 -1.94]',\n",
       " '[ 0.13  3.75 -2.17]',\n",
       " '[ 0.25  3.73 -2.33]',\n",
       " '[ 0.25  3.73 -2.33]',\n",
       " '[ 0.65  3.69 -2.65]',\n",
       " '[ 0.87  3.34 -2.63]',\n",
       " '[ 0.64 -1.82  0.52]',\n",
       " '[-0.05 -2.22  1.5 ]',\n",
       " '[-0.43 -2.32  1.84]',\n",
       " '[ 0.62 -1.56  0.28]',\n",
       " '[ 1.47  0.12 -1.84]',\n",
       " '[ 0.96  2.32 -2.74]',\n",
       " '[ 1.    2.27 -2.8 ]',\n",
       " '[ 0.02  3.69 -1.9 ]',\n",
       " '[-0.07  3.26 -1.75]',\n",
       " '[ 1.46  0.4  -2.05]',\n",
       " '[ 0.94  2.14 -2.78]',\n",
       " '[ 0.72  2.96 -2.81]',\n",
       " '[ 0.12  3.68 -2.17]',\n",
       " '[ 0.42  3.73 -2.38]',\n",
       " '[ 0.61  3.17 -2.69]',\n",
       " '[ 0.1   3.71 -2.17]',\n",
       " '[ 1.2   1.39 -2.51]',\n",
       " '[ 1.41 -0.15 -1.57]',\n",
       " '[ 0.88  2.6  -2.81]',\n",
       " '[ 0.8   2.74 -2.79]',\n",
       " '[ 0.86  2.61 -2.8 ]',\n",
       " '[-0.13  3.47 -1.83]',\n",
       " '[ 0.63  3.43 -2.68]',\n",
       " '[ 0.12  3.63 -2.13]',\n",
       " '[ 0.53  3.63 -2.36]',\n",
       " '[-0.07 -2.34  1.54]',\n",
       " '[ 0.71 -1.46  0.22]',\n",
       " '[ 0.37 -1.94  0.93]',\n",
       " '[-0.8  -1.37  2.31]',\n",
       " '[ 1.43  0.89 -2.4 ]',\n",
       " '[ 0.67  3.52 -2.43]',\n",
       " '[ 0.95  2.27 -2.59]',\n",
       " '[ 0.95  2.27 -2.59]',\n",
       " '[ 0.95  2.27 -2.59]',\n",
       " '[ 0.79  3.36 -2.59]',\n",
       " '[ 1.5   0.63 -2.3 ]',\n",
       " '[ 0.42  3.78 -2.37]',\n",
       " '[ 0.42  3.78 -2.37]',\n",
       " '[ 1.39  0.94 -2.43]',\n",
       " '[-0.79 -1.64  2.31]',\n",
       " '[-0.73 -1.5   2.3 ]',\n",
       " '[ 0.74  1.91 -1.62]',\n",
       " '[ 0.53  3.08 -2.54]',\n",
       " '[ 0.45  3.46 -2.33]',\n",
       " '[ 1.51  0.4  -2.18]',\n",
       " '[ 0.71  3.67 -2.64]',\n",
       " '[ 0.19  3.8  -2.27]',\n",
       " '[ 1.01  2.49 -2.73]',\n",
       " '[ 1.55  0.49 -2.25]',\n",
       " '[ 0.53  3.78 -2.51]',\n",
       " '[-0.18  3.35 -1.74]',\n",
       " '[ 0.18  3.52 -2.09]',\n",
       " '[ 1.56  0.36 -2.11]',\n",
       " '[ 0.65  3.12 -2.67]',\n",
       " '[ 1.41  1.02 -2.4 ]',\n",
       " '[-0.76 -1.97  2.26]',\n",
       " '[ 0.42 -2.11  0.98]',\n",
       " '[ 1.44  0.45 -2.15]',\n",
       " '[-0.26 -2.19  1.59]',\n",
       " '[ 1.51  0.21 -1.94]',\n",
       " '[ 0.22  3.74 -2.23]',\n",
       " '[ 0.53  3.75 -2.53]',\n",
       " '[ 0.57  3.8  -2.61]',\n",
       " '[ 1.02  1.92 -2.54]',\n",
       " '[ 1.35 -0.1  -1.51]',\n",
       " '[ 1.49  0.58 -2.26]',\n",
       " '[-0.02  3.57 -2.08]',\n",
       " '[ 0.29  3.8  -2.38]',\n",
       " '[ 0.83  2.62 -2.73]',\n",
       " '[ 0.15  3.77 -2.27]',\n",
       " '[ 1.34  1.44 -2.62]',\n",
       " '[ 1.48  0.37 -2.1 ]',\n",
       " '[ 0.18  3.75 -2.3 ]',\n",
       " '[ 0.31  3.84 -2.39]',\n",
       " '[-0.33  3.29 -1.6 ]',\n",
       " '[-0.23  3.33 -1.8 ]',\n",
       " '[ 0.06  3.69 -2.17]',\n",
       " '[ 0.06  3.64 -2.09]',\n",
       " '[ 0.22  3.72 -2.28]',\n",
       " '[ 1.22  2.11 -2.77]',\n",
       " '[ 0.37 -2.15  1.1 ]',\n",
       " '[ 1.51  0.23 -2.01]',\n",
       " '[ 1.46  0.26 -1.95]',\n",
       " '[ 0.6  -1.89  0.6 ]',\n",
       " '[-0.77 -1.45  2.28]',\n",
       " '[ 1.52  0.43 -2.19]',\n",
       " '[ 0.6   3.69 -2.57]',\n",
       " '[ 0.64  3.63 -2.59]',\n",
       " '[ 0.94  2.32 -2.77]',\n",
       " '[ 0.94  2.32 -2.77]',\n",
       " '[ 1.05  2.37 -2.77]',\n",
       " '[ 1.5   0.42 -2.14]',\n",
       " '[ 0.67  3.13 -2.64]',\n",
       " '[ 0.56  3.63 -2.55]',\n",
       " '[ 0.7   3.52 -2.65]',\n",
       " '[ 0.44  3.5  -2.4 ]',\n",
       " '[ 1.48  0.69 -2.31]',\n",
       " '[ 0.87  2.67 -2.71]',\n",
       " '[ 0.06  3.7  -2.15]',\n",
       " '[ 0.79  2.84 -2.74]',\n",
       " '[ 0.79  2.84 -2.74]',\n",
       " '[ 0.79  2.84 -2.74]',\n",
       " '[ 0.4   3.77 -2.4 ]',\n",
       " '[ 0.27  3.71 -2.42]',\n",
       " '[ 0.86  2.74 -2.68]',\n",
       " '[-0.78 -1.57  2.32]',\n",
       " '[-0.78 -1.36  2.3 ]',\n",
       " '[ 1.49  0.46 -2.18]',\n",
       " '[ 0.72  2.92 -2.74]',\n",
       " '[ 0.78  2.78 -2.73]',\n",
       " '[ 0.78  2.75 -2.75]',\n",
       " '[ 0.66  3.12 -2.74]',\n",
       " '[ 0.64  3.64 -2.61]',\n",
       " '[ 1.46  0.37 -2.06]',\n",
       " '[ 1.55  0.37 -2.17]',\n",
       " '[ 0.9   2.49 -2.81]',\n",
       " '[ 0.34  3.75 -2.35]',\n",
       " '[-0.09  3.59 -1.93]',\n",
       " '[ 0.86  3.23 -2.46]',\n",
       " '[ 1.53 -0.06 -1.81]',\n",
       " '[ 0.42  3.74 -2.41]',\n",
       " '[ 0.16  3.81 -2.26]',\n",
       " '[ 0.69  3.43 -2.77]',\n",
       " '[ 0.77  2.7  -2.68]',\n",
       " '[ 0.96  1.85 -2.56]',\n",
       " '[ 1.11  1.61 -2.57]',\n",
       " '[-0.77 -1.79  2.22]',\n",
       " '[ 0.13 -2.26  1.4 ]',\n",
       " '[ 0.8  -0.92 -0.26]',\n",
       " '[ 1.52  0.45 -2.23]',\n",
       " '[ 0.57  3.69 -2.6 ]',\n",
       " '[ 0.9   2.39 -2.75]',\n",
       " '[ 0.58  3.56 -2.6 ]',\n",
       " '[ 1.37  1.14 -2.46]',\n",
       " '[ 1.53  0.37 -2.17]',\n",
       " '[ 0.69  3.41 -2.74]',\n",
       " '[ 0.8   2.73 -2.79]',\n",
       " '[ 1.27  0.7  -2.15]',\n",
       " '[ 0.17 -2.12  1.27]',\n",
       " '[ 1.4   0.97 -2.44]',\n",
       " '[ 0.33  3.75 -2.41]',\n",
       " '[-0.06  3.64 -1.98]',\n",
       " '[ 0.09  3.7  -2.21]',\n",
       " '[ 0.62  3.54 -2.44]',\n",
       " '[ 0.48 -2.1   0.92]',\n",
       " '[ 1.31  1.52 -2.71]',\n",
       " '[ 0.73 -1.77  0.3 ]',\n",
       " '[-0.81 -1.37  2.33]',\n",
       " '[ 1.46  1.06 -2.46]',\n",
       " '[ 0.15  3.63 -2.25]',\n",
       " '[ 1.24  1.22 -2.46]',\n",
       " '[ 0.52  3.48 -2.45]',\n",
       " '[ 0.71  3.07 -2.54]',\n",
       " '[ 1.39  1.11 -2.44]',\n",
       " '[-0.17  3.52 -1.86]',\n",
       " '[ 0.41  3.72 -2.47]',\n",
       " '[-0.12  3.55 -1.92]',\n",
       " '[ 0.94  2.53 -2.6 ]',\n",
       " '[ 1.16 -0.11 -1.23]',\n",
       " '[ 0.73  2.82 -2.76]',\n",
       " '[ 0.7   3.15 -2.68]',\n",
       " '[-0.85 -1.27  2.26]',\n",
       " '[-0.54 -2.26  1.97]',\n",
       " '[ 1.46  0.69 -2.37]',\n",
       " '[ 0.41  3.61 -2.29]',\n",
       " '[ 1.4   0.8  -2.35]',\n",
       " '[ 0.84  2.55 -2.76]',\n",
       " '[ 1.2   1.86 -2.69]',\n",
       " '[ 1.46  0.5  -2.23]',\n",
       " '[ 0.71  3.56 -2.49]',\n",
       " '[ 1.29  1.09 -2.47]',\n",
       " '[ 0.83  2.66 -2.79]',\n",
       " '[-0.77 -2.01  2.22]',\n",
       " '[ 0.43 -2.14  1.01]',\n",
       " '[ 0.74 -1.73  0.24]',\n",
       " '[ 1.53  0.45 -2.25]',\n",
       " '[ 0.28  3.7  -2.36]',\n",
       " '[ 0.24  3.75 -2.35]',\n",
       " '[ 0.58  3.6  -2.47]',\n",
       " '[ 1.55  0.3  -2.14]',\n",
       " '[-0.15  3.45 -1.92]',\n",
       " '[ 0.26  3.67 -2.37]',\n",
       " '[ 0.46  3.76 -2.5 ]',\n",
       " '[ 0.69  3.57 -2.6 ]',\n",
       " '[ 0.93  2.64 -2.77]',\n",
       " '[ 1.57  0.3  -2.13]',\n",
       " '[-0.18  3.46 -1.96]',\n",
       " '[ 1.06  2.3  -2.76]',\n",
       " '[-0.71 -1.84  2.15]',\n",
       " '[ 0.19 -2.26  1.3 ]',\n",
       " '[ 0.35 -1.93  0.87]',\n",
       " '[ 1.49  0.57 -2.19]',\n",
       " '[-0.14  3.5  -1.92]',\n",
       " '[-0.24  3.36 -1.72]',\n",
       " '[ 0.29  3.86 -2.27]',\n",
       " '[ 0.45  2.35 -1.86]',\n",
       " '[ 1.52  0.5  -2.13]',\n",
       " '[ 0.67  3.49 -2.69]',\n",
       " '[ 0.32  3.78 -2.39]',\n",
       " '[ 0.06  3.53 -1.99]',\n",
       " '[ 0.01 -2.29  1.47]',\n",
       " '[ 0.14 -2.17  1.3 ]',\n",
       " '[-0.77 -1.87  2.3 ]',\n",
       " '[ 1.52  0.4  -2.13]',\n",
       " '[ 0.5   3.71 -2.44]',\n",
       " '[ 0.11  3.67 -2.25]',\n",
       " '[ 0.96  2.24 -2.67]',\n",
       " '[-0.27  3.24 -1.58]',\n",
       " '[-0.38  2.96 -1.35]',\n",
       " '[-0.07  3.61 -2.02]',\n",
       " '[-0.41  3.01 -1.24]',\n",
       " '[ 1.04 -0.5  -0.81]',\n",
       " '[ 1.48  0.56 -2.25]',\n",
       " '[ 0.2   3.73 -2.31]',\n",
       " '[ 0.45  3.78 -2.47]',\n",
       " '[-0.29  3.34 -1.65]',\n",
       " '[-0.28  3.35 -1.74]',\n",
       " '[-0.22  3.33 -1.75]',\n",
       " '[-0.29  2.72 -1.16]',\n",
       " '[ 0.62 -1.76  0.51]',\n",
       " '[ 1.4   1.05 -2.51]',\n",
       " '[ 1.38  0.85 -2.37]',\n",
       " '[ 0.4  -1.92  0.81]',\n",
       " '[-0.25 -2.38  1.69]',\n",
       " '[-0.21 -2.24  1.54]',\n",
       " '[ 1.32  1.06 -2.48]',\n",
       " '[ 0.79  2.8  -2.81]',\n",
       " '[ 1.02  2.02 -2.72]',\n",
       " '[ 0.96  2.67 -2.84]',\n",
       " '[ 1.51  0.34 -2.19]',\n",
       " '[ 0.35  3.83 -2.42]',\n",
       " '[ 0.66  3.17 -2.82]',\n",
       " '[ 0.66  3.15 -2.8 ]',\n",
       " '[ 0.66  3.15 -2.8 ]',\n",
       " '[ 0.92  2.7  -2.79]',\n",
       " '[ 1.35  1.18 -2.51]',\n",
       " '[ 0.15  3.58 -2.32]',\n",
       " '[ 0.16  3.73 -2.32]',\n",
       " '[ 0.37  3.72 -2.43]',\n",
       " '[ 0.27  3.7  -2.39]',\n",
       " '[ 1.02  2.48 -2.8 ]',\n",
       " '[-0.77 -1.76  2.29]',\n",
       " '[-0.74 -1.43  2.34]',\n",
       " '[ 1.5   0.43 -2.07]',\n",
       " '[ 0.59  3.53 -2.6 ]',\n",
       " '[ 0.43  3.79 -2.44]',\n",
       " '[ 1.1   1.84 -2.63]',\n",
       " '[ 1.5   0.84 -2.41]',\n",
       " '[ 0.75  2.78 -2.8 ]',\n",
       " '[ 0.84  2.4  -2.68]',\n",
       " '[ 1.22  0.79 -2.1 ]',\n",
       " '[ 1.38  0.62 -2.15]',\n",
       " '[ 1.51  0.67 -2.34]',\n",
       " '[ 0.62  2.8  -2.48]',\n",
       " '[ 0.62  2.8  -2.48]',\n",
       " '[ 0.85  3.36 -2.68]',\n",
       " '[-0.32 -2.38  1.78]',\n",
       " '[ 0.72 -1.7   0.41]',\n",
       " '[-0.79 -1.02  2.16]',\n",
       " '[ 1.37  0.83 -2.32]',\n",
       " '[ 0.62  3.65 -2.53]',\n",
       " '[ 0.9   2.35 -2.71]',\n",
       " '[-0.18  3.51 -1.8 ]',\n",
       " '[ 1.24  1.52 -2.65]',\n",
       " '[ 1.52  0.23 -2.05]',\n",
       " '[ 0.4   3.72 -2.37]',\n",
       " '[-0.17  3.4  -1.84]',\n",
       " '[-0.2   3.34 -1.77]',\n",
       " '[ 0.06  3.67 -2.17]',\n",
       " '[-0.36  3.16 -1.54]',\n",
       " '[-0.1   3.48 -1.94]',\n",
       " '[-0.23  3.4  -1.67]',\n",
       " '[-0.23  3.4  -1.67]',\n",
       " '[ 0.25  3.48 -2.14]',\n",
       " '[-0.61 -2.13  2.  ]',\n",
       " '[-0.77 -1.9   2.27]',\n",
       " '[ 1.33  1.35 -2.62]',\n",
       " '[ 0.17  3.65 -2.3 ]',\n",
       " '[ 0.28  3.71 -2.39]',\n",
       " '[ 0.38  3.75 -2.45]',\n",
       " '[-0.43  3.   -1.35]',\n",
       " '[ 0.1   3.62 -2.19]',\n",
       " '[ 0.32  3.81 -2.4 ]',\n",
       " '[ 0.63  3.67 -2.53]',\n",
       " '[ 1.46  0.76 -2.38]',\n",
       " '[ 1.31  0.51 -2.01]',\n",
       " '[-0.15  3.38 -1.93]',\n",
       " '[-0.29  3.14 -1.55]',\n",
       " '[-0.15  3.15 -1.81]',\n",
       " '[-0.77 -2.11  2.12]',\n",
       " '[-0.77 -1.42  2.31]',\n",
       " '[ 1.44  0.67 -2.28]',\n",
       " '[ 0.38  3.81 -2.45]',\n",
       " '[ 0.57  3.75 -2.55]',\n",
       " '[ 0.49  3.75 -2.48]',\n",
       " '[ 0.65  3.59 -2.66]',\n",
       " '[ 0.99 -0.57 -0.76]',\n",
       " '[ 1.56  0.19 -2.02]',\n",
       " '[ 1.12  1.5  -2.54]',\n",
       " '[ 1.27  1.06 -2.28]',\n",
       " '[ 0.52  3.77 -2.53]',\n",
       " '[ 0.86  2.58 -2.76]',\n",
       " '[ 0.88  3.21 -2.76]',\n",
       " '[ 1.55  0.38 -2.17]',\n",
       " '[ 0.43  3.8  -2.51]',\n",
       " '[ 0.32  3.77 -2.41]',\n",
       " '[ 0.51  3.82 -2.55]',\n",
       " '[ 1.51  0.67 -2.29]',\n",
       " '[ 0.6  -1.96  0.68]',\n",
       " '[ 0.63 -1.86  0.59]',\n",
       " '[-0.35 -2.37  1.78]',\n",
       " '[ 1.46  0.36 -2.07]',\n",
       " '[ 1.47  0.59 -2.27]',\n",
       " '[ 0.4  -1.96  0.84]',\n",
       " '[ 1.48  0.24 -2.03]',\n",
       " '[ 0.48  3.76 -2.52]',\n",
       " '[ 0.1   3.7  -2.27]',\n",
       " '[-0.04  3.63 -2.1 ]',\n",
       " '[ 0.11  3.66 -2.27]',\n",
       " '[ 0.28  3.81 -2.29]',\n",
       " '[ 0.62  3.55 -2.37]',\n",
       " '[ 1.5   0.33 -2.11]',\n",
       " '[ 0.04  3.62 -2.19]',\n",
       " '[ 0.09  3.75 -2.23]',\n",
       " '[ 0.92  2.43 -2.48]',\n",
       " '[ 1.24  1.71 -2.63]',\n",
       " '[-0.18  3.51 -1.91]',\n",
       " '[ 0.23  3.82 -2.19]',\n",
       " '[ 0.27  3.69 -2.43]',\n",
       " '[ 0.93  3.17 -2.66]',\n",
       " '[ 0.38 -2.16  1.11]',\n",
       " '[-0.33 -2.31  1.72]',\n",
       " '[-0.78 -1.52  2.33]',\n",
       " '[ 1.5   0.57 -2.22]',\n",
       " '[ 0.75  2.63 -2.63]',\n",
       " '[ 0.24  3.76 -2.28]',\n",
       " '[ 0.31  3.71 -2.26]',\n",
       " '[ 1.33  0.02 -1.6 ]',\n",
       " '[ 1.52  0.5  -2.25]',\n",
       " '[ 0.45  3.69 -2.47]',\n",
       " '[-0.24  3.4  -1.71]',\n",
       " '[-0.24  3.5  -1.82]',\n",
       " '[ 1.21  1.68 -2.66]',\n",
       " '[ 0.36 -2.19  1.14]',\n",
       " '[ 0.48 -2.06  0.91]',\n",
       " '[-0.33 -2.38  1.72]',\n",
       " '[-0.28 -2.29  1.62]',\n",
       " '[ 1.45  0.57 -2.19]',\n",
       " '[ 0.85  2.52 -2.8 ]',\n",
       " '[ 0.82  2.65 -2.8 ]',\n",
       " '[ 0.63  2.65 -2.57]',\n",
       " '[ 0.2   3.74 -2.26]',\n",
       " '[-0.05  3.54 -1.99]',\n",
       " '[ 0.74  2.78 -2.54]',\n",
       " '[ 1.49  0.52 -2.22]',\n",
       " '[ 0.84  2.59 -2.77]',\n",
       " '[ 0.75  2.62 -2.64]',\n",
       " '[ 0.97  2.07 -2.64]',\n",
       " '[ 0.97  2.07 -2.64]',\n",
       " '[ 1.14  1.92 -2.61]',\n",
       " '[-0.04 -2.36  1.48]',\n",
       " '[ 0.11 -2.22  1.29]',\n",
       " '[-0.8  -1.42  2.34]',\n",
       " '[ 1.49  0.48 -2.18]',\n",
       " '[ 0.92  2.47 -2.73]',\n",
       " '[ 0.06  3.65 -2.19]',\n",
       " '[ 1.27  0.68 -2.09]',\n",
       " '[ 0.61  3.57 -2.65]',\n",
       " '[ 0.88  2.97 -2.76]',\n",
       " '[ 1.56  0.35 -2.15]',\n",
       " '[ 0.55  3.78 -2.57]',\n",
       " '[ 0.55  3.78 -2.57]',\n",
       " '[ 0.71  3.32 -2.78]',\n",
       " '[ 1.4   0.12 -1.73]',\n",
       " '[ 0.99 -0.95 -0.39]',\n",
       " '[ 1.05  1.49 -2.24]',\n",
       " '[ 0.62  3.62 -2.65]',\n",
       " '[ 0.44  3.39 -2.31]',\n",
       " '[ 0.37  2.94 -1.76]',\n",
       " '[-0.42 -2.42  1.86]',\n",
       " '[ 0.16 -2.21  1.31]',\n",
       " '[-0.82 -1.23  2.3 ]',\n",
       " '[ 1.18  2.04 -2.76]',\n",
       " '[ 0.34  3.72 -2.35]',\n",
       " '[ 1.12  1.67 -2.69]',\n",
       " '[ 1.51  0.81 -2.4 ]',\n",
       " '[ 0.43  3.79 -2.45]',\n",
       " '[ 0.43  3.79 -2.45]',\n",
       " '[ 0.83  2.44 -2.73]',\n",
       " '[ 0.97  2.32 -2.78]',\n",
       " '[-0.78 -1.76  2.3 ]',\n",
       " '[-0.8  -1.37  2.34]',\n",
       " '[ 1.51  0.53 -2.26]',\n",
       " '[ 0.75  3.51 -2.44]',\n",
       " '[ 1.13 -0.74 -0.77]',\n",
       " '[ 0.66  3.64 -2.6 ]',\n",
       " '[ 0.9   2.59 -2.76]',\n",
       " '[ 1.09  2.29 -2.75]',\n",
       " '[ 1.5   0.52 -2.27]',\n",
       " '[ 0.8   3.24 -2.76]',\n",
       " '[ 1.53  0.38 -2.14]',\n",
       " '[ 0.74  3.42 -2.7 ]',\n",
       " '[ 0.99  3.05 -2.72]',\n",
       " '[ 1.45  0.76 -2.36]',\n",
       " '[ 1.08  2.46 -2.81]',\n",
       " '[-0.8  -1.53  2.33]',\n",
       " '[-0.67 -1.53  2.26]',\n",
       " '[ 1.5   0.61 -2.28]',\n",
       " '[ 0.12  3.66 -2.24]',\n",
       " '[-0.1   3.44 -1.93]',\n",
       " '[ 0.56  3.7  -2.51]',\n",
       " '[ 0.29  3.65 -2.36]',\n",
       " '[ 0.96  3.04 -2.64]',\n",
       " '[ 1.51  0.55 -2.24]',\n",
       " '[-0.02  3.58 -2.14]',\n",
       " '[ 0.11  3.68 -2.21]',\n",
       " '[-0.09  3.52 -1.97]',\n",
       " '[ 1.27  0.54 -1.98]',\n",
       " '[ 0.    3.61 -2.13]',\n",
       " '[ 0.19  3.26 -2.08]',\n",
       " '[ 1.33  1.22 -2.57]',\n",
       " '[ 0.57  3.72 -2.56]',\n",
       " '[ 0.36  3.68 -2.44]',\n",
       " '[-0.4   2.99 -1.45]',\n",
       " '[-0.1   3.48 -1.99]',\n",
       " '[ 0.26  3.69 -2.37]',\n",
       " '[-0.01  3.17 -1.91]',\n",
       " '[ 0.12 -2.16  1.36]',\n",
       " '[ 1.26 -0.48 -1.16]',\n",
       " '[-0.78 -2.09  2.23]',\n",
       " '[ 1.45  0.55 -2.19]',\n",
       " '[ 0.21  3.74 -2.31]',\n",
       " '[ 0.62  3.65 -2.52]',\n",
       " '[ 0.92  3.05 -2.66]',\n",
       " '[ 1.45  0.7  -2.31]',\n",
       " '[-0.16  3.4  -1.81]',\n",
       " '[-0.36  3.12 -1.53]',\n",
       " '[ 0.28  3.69 -2.29]',\n",
       " '[ 0.34  3.47 -2.2 ]',\n",
       " '[ 1.43  0.86 -2.37]',\n",
       " '[ 0.18  3.66 -2.28]',\n",
       " '[ 0.41  3.66 -2.36]',\n",
       " '[ 1.52  0.64 -2.27]',\n",
       " '[ 0.77  3.54 -2.56]',\n",
       " '[-0.71 -2.2   2.09]',\n",
       " '[-0.26 -2.33  1.73]',\n",
       " '[-0.03 -2.11  1.44]',\n",
       " '[ 1.52  0.64 -2.23]',\n",
       " '[ 0.45  3.82 -2.45]',\n",
       " '[ 0.67  3.6  -2.62]',\n",
       " '[ 0.63  3.7  -2.59]',\n",
       " '[ 0.49  3.81 -2.47]',\n",
       " '[ 0.49  3.81 -2.47]',\n",
       " '[ 0.63  3.66 -2.54]',\n",
       " '[ 1.52  0.19 -1.97]',\n",
       " '[ 0.19  3.74 -2.31]',\n",
       " '[ 0.7   3.09 -2.71]',\n",
       " '[ 1.24  0.74 -2.01]',\n",
       " '[ 1.37  0.48 -1.98]',\n",
       " '[ 1.49  0.85 -2.34]',\n",
       " '[ 0.74  3.02 -2.69]',\n",
       " '[ 0.77  2.7  -2.64]',\n",
       " '[ 0.26  3.8  -2.28]',\n",
       " '[ 0.63  3.74 -2.66]',\n",
       " '[ 1.31  1.67 -2.61]',\n",
       " '[ 0.63 -1.85  0.66]',\n",
       " '[ 1.29 -0.11 -1.38]',\n",
       " '[ 0.95 -1.37 -0.13]',\n",
       " '[-0.83 -1.05  2.24]',\n",
       " '[ 1.42  0.6  -2.2 ]',\n",
       " '[ 0.61  3.65 -2.48]',\n",
       " '[-0.25  3.32 -1.66]',\n",
       " '[ 1.37  0.84 -2.33]',\n",
       " '[ 1.52  0.38 -2.17]',\n",
       " '[ 1.13  1.31 -2.37]',\n",
       " '[ 0.64  3.53 -2.34]',\n",
       " '[ 1.54  0.42 -2.18]',\n",
       " '[ 0.48  3.74 -2.45]',\n",
       " '[-0.03  3.54 -2.03]',\n",
       " '[-0.15  3.42 -1.89]',\n",
       " '[ 0.28  3.72 -2.36]',\n",
       " '[ 0.85  3.14 -2.3 ]',\n",
       " '[-0.76 -1.8   2.27]',\n",
       " '[-0.72 -1.57  2.32]',\n",
       " '[ 1.43  0.88 -2.4 ]',\n",
       " '[ 0.48  3.7  -2.48]',\n",
       " '[ 0.62  3.43 -2.48]',\n",
       " '[ 0.69  3.23 -2.78]',\n",
       " '[ 0.44  3.52 -2.22]',\n",
       " '[ 1.52  0.22 -2.05]',\n",
       " '[ 0.75  3.21 -2.79]',\n",
       " '[ 0.62  3.59 -2.64]',\n",
       " '[ 0.94  2.36 -2.74]',\n",
       " '[ 1.06  2.15 -2.68]',\n",
       " '[ 0.31 -2.24  1.22]',\n",
       " '[ 1.05 -1.27 -0.45]',\n",
       " '[-0.79 -1.15  2.23]',\n",
       " '[ 1.48  0.82 -2.41]',\n",
       " '[ 0.71  3.53 -2.71]',\n",
       " '[ 0.6   3.69 -2.58]',\n",
       " '[ 0.58  3.76 -2.49]',\n",
       " '[ 0.5   3.75 -2.43]',\n",
       " '[ 1.12  2.25 -2.75]',\n",
       " '[ 1.47  0.87 -2.42]',\n",
       " '[ 1.11  1.41 -2.4 ]',\n",
       " '[ 1.11  1.41 -2.4 ]',\n",
       " '[ 0.7   3.56 -2.66]',\n",
       " '[ 0.77  2.81 -2.75]',\n",
       " '[ 0.77  2.81 -2.75]',\n",
       " '[ 0.63  3.27 -2.67]',\n",
       " '[ 1.45  0.68 -2.3 ]',\n",
       " '[ 0.33 -2.1   1.11]',\n",
       " '[ 0.39 -1.94  0.91]',\n",
       " '[-0.72 -1.69  2.32]',\n",
       " '[ 1.49  0.31 -2.08]',\n",
       " '[ 0.76  2.58 -2.72]',\n",
       " '[ 0.83  2.67 -2.73]',\n",
       " '[ 0.79  2.94 -2.76]',\n",
       " '[ 0.24  3.77 -2.37]',\n",
       " '[ 0.61  3.12 -2.67]',\n",
       " '[ 0.9   2.7  -2.82]',\n",
       " '[ 1.51  0.66 -2.33]',\n",
       " '[ 1.03  2.11 -2.73]',\n",
       " '[ 0.02  3.64 -2.05]',\n",
       " '[ 0.64  3.69 -2.61]',\n",
       " '[ 1.2   1.57 -2.62]',\n",
       " '[ 0.54 -2.04  0.81]',\n",
       " '[ 1.43  0.22 -1.97]',\n",
       " '[ 0.78 -1.73  0.26]',\n",
       " '[-0.8  -1.34  2.32]',\n",
       " '[ 1.47  0.87 -2.45]',\n",
       " '[ 1.02  1.81 -2.58]',\n",
       " '[ 1.28  1.28 -2.54]',\n",
       " '[ 1.54  0.24 -2.08]',\n",
       " '[ 0.56  3.66 -2.65]',\n",
       " '[ 0.66  3.4  -2.79]',\n",
       " '[ 1.41  0.85 -2.35]',\n",
       " '[ 1.57  0.62 -2.31]',\n",
       " '[ 0.84  2.64 -2.77]',\n",
       " '[ 0.56  3.66 -2.55]',\n",
       " '[ 0.98  2.82 -2.88]',\n",
       " '[-0.13 -2.41  1.66]',\n",
       " '[ 0.88 -1.59  0.03]',\n",
       " '[-0.76 -1.63  2.32]',\n",
       " '[ 1.52  0.46 -2.22]',\n",
       " '[ 0.59  3.53 -2.47]',\n",
       " '[-0.12  3.46 -1.79]',\n",
       " '[-0.27  3.22 -1.54]',\n",
       " '[ 0.84  1.8  -2.29]',\n",
       " '[ 1.39  1.   -2.47]',\n",
       " '[ 1.53  0.6  -2.33]',\n",
       " '[ 0.82  2.69 -2.76]',\n",
       " '[ 1.19  1.27 -2.42]',\n",
       " '[ 0.67  2.55 -2.5 ]',\n",
       " '[ 1.39  0.83 -2.37]',\n",
       " '[ 1.41  0.99 -2.48]',\n",
       " '[-0.06  3.6  -1.97]',\n",
       " '[ 0.65  3.59 -2.72]',\n",
       " '[ 0.33  3.36 -2.27]',\n",
       " '[-0.29 -2.39  1.75]',\n",
       " '[ 0.95 -1.44 -0.23]',\n",
       " '[-0.75 -1.19  2.16]',\n",
       " '[ 1.55  0.4  -2.14]',\n",
       " '[ 0.11  3.72 -2.18]',\n",
       " '[-0.07  3.59 -2.04]',\n",
       " '[ 0.82  3.18 -2.66]',\n",
       " '[ 1.56  0.4  -2.13]',\n",
       " '[-0.14  3.45 -1.86]',\n",
       " '[-0.1   3.59 -2.  ]',\n",
       " '[ 0.9   2.16 -2.56]',\n",
       " '[ 0.67  3.37 -2.41]',\n",
       " '[ 0.21 -2.23  1.32]',\n",
       " '[ 1.   -0.85 -0.53]',\n",
       " '[ 1.38 -0.17 -1.54]',\n",
       " '[ 0.36 -2.09  1.03]',\n",
       " '[-0.71 -1.63  2.28]',\n",
       " '[ 1.56  0.45 -2.18]',\n",
       " '[ 0.27  3.77 -2.31]',\n",
       " '[ 0.19  3.77 -2.27]',\n",
       " '[ 1.09  1.28 -2.31]',\n",
       " '[ 1.45 -0.06 -1.68]',\n",
       " '[ 1.56  0.38 -2.1 ]',\n",
       " '[ 0.62  3.22 -2.69]',\n",
       " '[ 1.14  1.44 -2.46]',\n",
       " '[ 0.24  3.78 -2.22]',\n",
       " '[ 0.24  3.78 -2.22]',\n",
       " '[ 0.58  3.21 -2.68]',\n",
       " '[ 0.87  2.85 -2.75]',\n",
       " '[ 1.55  0.4  -2.17]',\n",
       " '[ 0.58  3.73 -2.58]',\n",
       " '[ 0.54  3.71 -2.59]',\n",
       " '[ 0.54  3.71 -2.59]',\n",
       " '[ 1.08  1.77 -2.58]',\n",
       " '[-0.33 -2.4   1.8 ]',\n",
       " '[ 0.65 -1.57  0.44]',\n",
       " '[ 1.53  0.41 -2.11]',\n",
       " '[ 1.53  0.41 -2.11]',\n",
       " '[ 1.47  0.73 -2.25]',\n",
       " '[-0.08 -2.28  1.55]',\n",
       " '[-0.76 -1.42  2.33]',\n",
       " '[ 1.53  0.47 -2.18]',\n",
       " '[-0.22  3.34 -1.76]',\n",
       " '[-0.36  2.85 -1.12]',\n",
       " '[ 1.52  0.59 -2.32]',\n",
       " '[-0.39  3.11 -1.41]',\n",
       " '[-0.13  3.49 -1.86]',\n",
       " '[-0.13  3.49 -1.86]',\n",
       " '[-0.14  3.14 -1.57]',\n",
       " '[ 1.45  0.65 -2.18]',\n",
       " '[ 0.2   3.58 -2.23]',\n",
       " '[ 0.24  3.78 -2.34]',\n",
       " '[-0.17  3.42 -1.94]',\n",
       " '[-0.05  3.27 -1.94]',\n",
       " '[-0.27 -2.38  1.74]',\n",
       " '[ 0.62 -1.33  0.3 ]',\n",
       " '[ 0.95 -1.31 -0.28]',\n",
       " '[-0.18 -2.4   1.67]',\n",
       " '[-0.05 -2.2   1.44]',\n",
       " '[ 1.47  0.65 -2.29]',\n",
       " '[ 0.26  3.84 -2.38]',\n",
       " '[ 0.54  3.57 -2.3 ]',\n",
       " '[ 1.53  0.38 -2.17]',\n",
       " '[ 0.14  3.8  -2.31]',\n",
       " '[ 0.56  3.46 -2.59]',\n",
       " '[ 0.65  3.31 -2.55]',\n",
       " '[ 1.49  0.17 -1.94]',\n",
       " '[ 0.5   3.44 -2.68]',\n",
       " '[-0.09  3.66 -2.01]',\n",
       " '[ 0.38  3.85 -2.45]',\n",
       " '[ 1.35  1.18 -2.58]',\n",
       " '[ 0.3  -2.23  1.26]',\n",
       " ...]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "46ef727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_probs = pd.DataFrame(new_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2e61fdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ 0.38 -1.06  0.34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.05 -2.19  1.46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ 0.59  3.03 -2.52]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ 0.09  3.73 -2.09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.02  3.64 -2.  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>[-0.07  3.36 -1.88]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>[ 1.51  0.57 -2.19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>[ 0.99  2.18 -2.6 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>[ 0.92  3.2  -2.66]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>[-0.74 -2.08  2.2 ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "0     [ 0.38 -1.06  0.34]\n",
       "1     [-0.05 -2.19  1.46]\n",
       "2     [ 0.59  3.03 -2.52]\n",
       "3     [ 0.09  3.73 -2.09]\n",
       "4     [-0.02  3.64 -2.  ]\n",
       "...                   ...\n",
       "1253  [-0.07  3.36 -1.88]\n",
       "1254  [ 1.51  0.57 -2.19]\n",
       "1255  [ 0.99  2.18 -2.6 ]\n",
       "1256  [ 0.92  3.2  -2.66]\n",
       "1257  [-0.74 -2.08  2.2 ]\n",
       "\n",
       "[1258 rows x 1 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7f0476bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5967"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4709+1258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5c24ef42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'feature_tensor', 'input_ids', 'labels', 'sentence', 'split', 'text', 'token_type_ids', 'topic_and_full_sentence', 'topic_full_sentence_structural_fts_combined', 'topic_full_sentence_stuctural_fts'],\n",
       "    num_rows: 4709\n",
       "})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cc8b39fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46b07d31a4743e9858b6383fda624e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9520416"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.to_csv(\"train_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1a02cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7fb9759d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Topic: Should students be taught to compete or to cooperate? Sentence: From this point of view, I firmly believe that we should attach more importance to cooperation during primary education. Structural features: One. Yes. No. Yes. Yes.'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['topic_full_sentence_structural_fts_combined'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fb0cad16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4709, 12)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b5305b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02dab0f0be59476b9cc119db8cd6e482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2403992"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.to_csv('test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "85706db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8e870d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 12)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f7249d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['class_probs'] = df_train_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "72ffc50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[-0.82 -1.38  2.36]'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['class_probs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5645d832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['class_probs'] = df_test_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4c59cade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ 0.99  3.05 -2.72]'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['class_probs'][771]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b15b771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_s = df_test['class_probs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6e4b8bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_s = try_s.replace('[', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8007530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_s = try_s.replace(']','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4d32cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_s = try_s.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e9bd4677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.38 -1.06  0.34'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "644d5928",
   "metadata": {},
   "outputs": [],
   "source": [
    "try_l = try_s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0f8a449b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.38', '-1.06', '0.34']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "038feca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_str = try_l[0] + \", \" + try_l[1] + ', ' + try_l[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4fc9a952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.38, -1.06, 0.34'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make the concat function (done)\n",
    "# round the float (done)\n",
    "# run it on train dataset (done)\n",
    "# run it on test dataset (done)\n",
    "# make dataset object out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ee6d0290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'attention_mask', 'feature_tensor', 'input_ids', 'labels',\n",
       "       'sentence', 'split', 'text', 'token_type_ids',\n",
       "       'topic_and_full_sentence',\n",
       "       'topic_full_sentence_structural_fts_combined',\n",
       "       'topic_full_sentence_stuctural_fts', 'class_probs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "42edf518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'attention_mask', 'feature_tensor', 'input_ids', 'labels',\n",
       "       'sentence', 'split', 'text', 'token_type_ids',\n",
       "       'topic_and_full_sentence',\n",
       "       'topic_full_sentence_structural_fts_combined',\n",
       "       'topic_full_sentence_stuctural_fts', 'class_probs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a0356295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_probs_w_fts(x):\n",
    "    \n",
    "    text_s = x.topic_full_sentence_structural_fts_combined\n",
    "    probs = x.class_probs\n",
    "    \n",
    "    probs = probs.replace('[', '')\n",
    "    probs = probs.replace(']','')\n",
    "    probs = probs.lstrip()\n",
    "    probs_l = probs.split()\n",
    "    probs = probs_l[0] + \", \" + probs_l[1] + ', ' + probs_l[2]\n",
    "    \n",
    "    new_ft = text_s + ' Class probabilities: ' + probs\n",
    "    \n",
    "    return new_ft   \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "28214122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Topic: Should students be taught to compete or to cooperate? Sentence: From this point of view, I firmly believe that we should attach more importance to cooperation during primary education. Structural features: One. Yes. No. Yes. Yes. Class probabilities: -0.82, -1.38, 2.36'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_probs_w_fts(df_train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3130b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['strct_fts_w_probs'] = df_train.apply(lambda x: concat_probs_w_fts(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8442b5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5 ,  0.54, -2.27], dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_probs[190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4d008955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Topic: Television is the culprit for destroying communication between friends & family. Sentence: In spite of enjoying watching television shows, it is really time consuming task. Structural features: Two. No. No. Yes. No. Class probabilities: 1.5, 0.54, -2.27',\n",
       " 'Topic: Television is the culprit for destroying communication between friends & family. Sentence: In spite of enjoying watching television shows, it is really time consuming task. Structural features: Two. No. No. Yes. No.')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['strct_fts_w_probs'][190], df_train['topic_full_sentence_structural_fts_combined'][190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c77e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train is correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f6a2dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['strct_fts_w_probs'] = df_test.apply(lambda x: concat_probs_w_fts(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "961d7243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83,  2.81, -2.82], dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_probs[230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e284e940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Topic: Some young adults want independence from their parents quickly. Sentence: There will not be such worries when young adults live in their own home, because parents will take care for them. Structural features: Two. No. No. No. No. Class probabilities: 0.83, 2.81, -2.82'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['strct_fts_w_probs'][230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "227bc746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "687a9651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'attention_mask', 'feature_tensor', 'input_ids', 'labels',\n",
       "       'sentence', 'split', 'text', 'token_type_ids',\n",
       "       'topic_and_full_sentence',\n",
       "       'topic_full_sentence_structural_fts_combined',\n",
       "       'topic_full_sentence_stuctural_fts', 'class_probs',\n",
       "       'strct_fts_w_probs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "92196fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['split', 'text', 'labels', 'sentence', 'topic_and_full_sentence', 'topic_full_sentence_stuctural_fts', 'topic_full_sentence_structural_fts_combined', 'feature_tensor', 'strct_fts_w_probs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2bee54b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['split', 'text', 'labels', 'sentence', 'topic_and_full_sentence',\n",
       "       'topic_full_sentence_stuctural_fts',\n",
       "       'topic_full_sentence_structural_fts_combined', 'feature_tensor',\n",
       "       'strct_fts_w_probs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e674c8bd",
   "metadata": {},
   "source": [
    "['split', 'text', 'labels', 'sentence', 'topic_and_full_sentence', 'topic_full_sentence_stuctural_fts', 'topic_full_sentence_structural_fts_combined', 'feature_tensor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d5e379e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[['split', 'text', 'labels', 'sentence', 'topic_and_full_sentence', 'topic_full_sentence_stuctural_fts', 'topic_full_sentence_structural_fts_combined', 'feature_tensor', 'strct_fts_w_probs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a08f19a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['split', 'text', 'labels', 'sentence', 'topic_and_full_sentence',\n",
       "       'topic_full_sentence_stuctural_fts',\n",
       "       'topic_full_sentence_structural_fts_combined', 'feature_tensor',\n",
       "       'strct_fts_w_probs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c801576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d82a3281",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_test = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1a2c6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\"train\": dataset_train, \"test\": dataset_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f50104dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['split', 'text', 'labels', 'sentence', 'topic_and_full_sentence', 'topic_full_sentence_stuctural_fts', 'topic_full_sentence_structural_fts_combined', 'feature_tensor', 'strct_fts_w_probs'],\n",
       "        num_rows: 4709\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['split', 'text', 'labels', 'sentence', 'topic_and_full_sentence', 'topic_full_sentence_stuctural_fts', 'topic_full_sentence_structural_fts_combined', 'feature_tensor', 'strct_fts_w_probs'],\n",
       "        num_rows: 1258\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2fb704a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset, os.path.join('/notebooks/cascade_bert', 'pe_dataset_w_bert_probs.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841a85e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022734ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032d0fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e7bfbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356398a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0d7a79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].add_column('bert_probs_z', new_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e55111c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_445/3960316631.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bert_probs_z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1857\u001b[0;31m         return self._getitem(\n\u001b[0m\u001b[1;32m   1858\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m         formatted_output = format_table(\n\u001b[0m\u001b[1;32m   1851\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpython_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36mformat_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"torch.Tensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36mrecursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive_tensorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types, disable_tqdm)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     disable_tqdm = (\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36m_recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytorch tensors cannot be instantied from an array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstruct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubstruct\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36m_tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mdefault_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_tensor_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "dataset['train']['bert_probs_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2c3876f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "142c9ce0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Added column's length must match table's length. Expected length 4709 but got length 235",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_445/1547488990.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert_probs_4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m         }\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36madd_column\u001b[0;34m(self, name, column, new_fingerprint)\u001b[0m\n\u001b[1;32m   3348\u001b[0m         \u001b[0mcolumn_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInMemoryTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pydict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3349\u001b[0m         \u001b[0;31m# Concatenate tables horizontally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3350\u001b[0;31m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenationTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_table\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3351\u001b[0m         \u001b[0;31m# Update features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3352\u001b[0m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/table.py\u001b[0m in \u001b[0;36mfrom_tables\u001b[0;34m(cls, tables, axis)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mtable_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/table.py\u001b[0m in \u001b[0;36mfrom_blocks\u001b[0;34m(cls, blocks)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTableBlockContainer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"ConcatenationTable\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTableBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/table.py\u001b[0m in \u001b[0;36m_consolidate_blocks\u001b[0;34m(cls, blocks)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/table.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(cls, blocks, axis)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0mmerged_blocks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# both\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mmerged_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_block\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmerged_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                 merged_blocks = cls._merge_blocks(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/table.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0mmerged_blocks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# both\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mmerged_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_block\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmerged_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                 merged_blocks = cls._merge_blocks(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/table.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(cls, blocks, axis)\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mis_in_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInMemoryTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_in_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m                     \u001b[0mblock_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mInMemoryTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concat_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m                 \u001b[0mmerged_blocks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# both\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/table.py\u001b[0m in \u001b[0;36m_concat_blocks\u001b[0;34m(blocks, axis)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                         \u001b[0mpa_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table.append_column\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/table.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.Table.add_column\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Added column's length must match table's length. Expected length 4709 but got length 235"
     ]
    }
   ],
   "source": [
    "dataset['train'] = dataset['train'].add_column('bert_probs_4', nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a2db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2edb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e98c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d7c4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ee6dc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'feature_tensor', 'input_ids', 'labels', 'sentence', 'split', 'text', 'token_type_ids', 'topic_and_full_sentence', 'topic_full_sentence_structural_fts_combined', 'topic_full_sentence_stuctural_fts'],\n",
       "    num_rows: 4709\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4a02657",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3]:\n",
    "    \n",
    "    dataset['train'] = dataset['train'].add_column('bert_probs' + str(i), train_probs[:,i-1])\n",
    "    dataset['test'] = dataset['test'].add_column('bert_probs' + str(i), test_probs[:,i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "159a0301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'feature_tensor', 'input_ids', 'labels', 'sentence', 'split', 'text', 'token_type_ids', 'topic_and_full_sentence', 'topic_full_sentence_structural_fts_combined', 'topic_full_sentence_stuctural_fts', 'bert_probs1', 'bert_probs2', 'bert_probs3'],\n",
       "    num_rows: 4709\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fa05033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8163,  1.5404,  0.3230,  ...,  0.8422,  1.2905, -0.6934])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['bert_probs1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1078c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate to get new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0b82c6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_probs_list = []\n",
    "\n",
    "for k in range(0,4709,1):\n",
    "    \n",
    "    new_str = str(round(dataset['train']['bert_probs1'][k].tolist(), 2)) + ' ' + str(round(dataset['train']['bert_probs1'][k].tolist(), 2)) + ' ' + str(round(dataset['train']['bert_probs1'][k].tolist(), 2))\n",
    "    \n",
    "    train_probs_list.append(new_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "359ceb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4709"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_probs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5686077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs_list = []\n",
    "\n",
    "for k in range(0,1258,1):\n",
    "    \n",
    "    new_str = str(round(dataset['test']['bert_probs1'][k].tolist(), 2)) + ' ' + str(round(dataset['test']['bert_probs1'][k].tolist(), 2)) + ' ' + str(round(dataset['test']['bert_probs1'][k].tolist(), 2))\n",
    "    \n",
    "    test_probs_list.append(new_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b9acb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_probs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9451e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].add_column('full_bert_probs_2', train_probs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb01c8e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_445/1330197930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_bert_probs_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1857\u001b[0;31m         return self._getitem(\n\u001b[0m\u001b[1;32m   1858\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m         formatted_output = format_table(\n\u001b[0m\u001b[1;32m   1851\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpython_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36mformat_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"torch.Tensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36mrecursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive_tensorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types, disable_tqdm)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     disable_tqdm = (\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36m_recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytorch tensors cannot be instantied from an array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstruct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubstruct\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36m_tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mdefault_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_tensor_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "dataset['train']['full_bert_probs_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4fea23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be6f695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad4b9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97345a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319848f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "4e823f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].remove_columns(['bert_probs_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "6cb49e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test'] = dataset['test'].remove_columns(['bert_probs_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "e2cc86b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'feature_tensor', 'input_ids', 'labels', 'sentence', 'split', 'text', 'token_type_ids', 'topic_and_full_sentence', 'topic_full_sentence_structural_fts_combined', 'topic_full_sentence_stuctural_fts', 'bert_probs1', 'bert_probs2', 'bert_probs3'],\n",
       "    num_rows: 4709\n",
       "})"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "79c40c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'test']:\n",
    "\n",
    "\n",
    "    a = np.array(dataset[split]['bert_probs1']).round(2).astype(str)\n",
    "\n",
    "    b = np.array(dataset[split]['bert_probs2']).round(2).astype(str)\n",
    "\n",
    "    c = np.array(dataset[split]['bert_probs3']).round(2).astype(str)\n",
    "\n",
    "    tmp = np.core.defchararray.add(a, ' ')\n",
    "\n",
    "    tmp = np.core.defchararray.add(tmp, b)\n",
    "\n",
    "    tmp = np.core.defchararray.add(tmp, ' ')\n",
    "\n",
    "    tmp = np.core.defchararray.add(tmp, c)\n",
    "    \n",
    "    tmp = list(tmp)\n",
    "    \n",
    "    print(type(tmp))\n",
    "    \n",
    "    dataset[split] = dataset[split].add_column('bert_probs_str', tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "9f94240f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'feature_tensor', 'input_ids', 'labels', 'sentence', 'split', 'text', 'token_type_ids', 'topic_and_full_sentence', 'topic_full_sentence_structural_fts_combined', 'topic_full_sentence_stuctural_fts', 'bert_probs1', 'bert_probs2', 'bert_probs3', 'bert_probs_str'],\n",
       "    num_rows: 4709\n",
       "})"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "8607d40f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_154/2857532110.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bert_probs_str'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1857\u001b[0;31m         return self._getitem(\n\u001b[0m\u001b[1;32m   1858\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m         formatted_output = format_table(\n\u001b[0m\u001b[1;32m   1851\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpython_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36mformat_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"torch.Tensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36mrecursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive_tensorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types, disable_tqdm)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     disable_tqdm = (\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36m_recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytorch tensors cannot be instantied from an array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstruct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubstruct\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36m_tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mdefault_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_tensor_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "type(dataset['train']['bert_probs_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "9c5ff0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_1 = np.array(['a']*len(dataset['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "6ddfbd8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'a', 'a', ..., 'a', 'a', 'a'], dtype='<U1')"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "90042288",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].add_column('bert_probs_str_dummy_4', tmp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "5d2ec5e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_154/2117880570.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bert_probs_str_dummy_4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1857\u001b[0;31m         return self._getitem(\n\u001b[0m\u001b[1;32m   1858\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m         formatted_output = format_table(\n\u001b[0m\u001b[1;32m   1851\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpython_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36mformat_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"torch.Tensor\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36mrecursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive_tensorize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types, disable_tqdm)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     disable_tqdm = (\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36m_recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytorch tensors cannot be instantied from an array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstruct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubstruct\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/formatting/torch_formatter.py\u001b[0m in \u001b[0;36m_tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mdefault_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_tensor_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recursive_tensorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "dataset['train']['bert_probs_str_dummy_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2875ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f60d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0fe5671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "NUM_LABELS = labels.num_classes\n",
    "BATCH_SIZE = 48\n",
    "NB_EPOCHS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24754dfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e1cca082c7473c9e39569e4e54cd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=NUM_LABELS)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427dfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d26579a3",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 27,
     "id": "521987db-56d5-4e71-95af-7d1fb4a06e3f",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/transformers/main_classes/trainer.html\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss_fct = nn.CrossEntropyLoss()#(weight=class_weights)\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87183186",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 28,
     "id": "06697293-0ef4-4d24-95a9-6ca0ed569b51",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a906bef8374f4a2aaa0e9e1d4524f563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = load_metric('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    return metric.compute(predictions=predictions, references=labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3558aa9f",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 29,
     "id": "956f8a45-f8bd-42a5-b829-5e2b0e82cf42",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # output\n",
    "    output_dir=RESULTS_FOLDER,          \n",
    "    \n",
    "    #params\n",
    "    num_train_epochs=NB_EPOCHS,               # nb of epochs\n",
    "    per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,    # cf. paper Sun et al.\n",
    "    learning_rate=1e-5,#2e-5,                 # cf. paper Sun et al.\n",
    "#     warmup_steps=500,                         # number of warmup steps for learning rate scheduler\n",
    "    warmup_ratio=0.1,                         # cf. paper Sun et al.\n",
    "    weight_decay=0.01,                        # strength of weight decay\n",
    "    \n",
    "    #eval\n",
    "    evaluation_strategy=\"steps\",              # cf. paper Sun et al.\n",
    "    eval_steps=20,                            # cf. paper Sun et al.\n",
    "    \n",
    "    # log\n",
    "    logging_dir=\"/notebooks/Results/bert_sequence_classification/tb_logs\",  \n",
    "    logging_strategy='steps',\n",
    "    logging_steps=20,\n",
    "    \n",
    "    # save\n",
    "    save_strategy='steps',\n",
    "    save_total_limit=2,\n",
    "    #save_steps=20, # default 500\n",
    "    load_best_model_at_end=True,              # cf. paper Sun et al.\n",
    "    # metric_for_best_model='eval_loss' \n",
    "    metric_for_best_model='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf654831",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 30,
     "id": "219545f7-5aff-4d0c-87e2-4ca28a6e7acc",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "trainer = CustomTrainer( # Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db965f65",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 31,
     "id": "b524a80a-ccf0-41f4-a015-e4ba2913fdc4",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running training *****\n",
      "  Num examples = 3767\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 474\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='474' max='474' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [474/474 06:04, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.963300</td>\n",
       "      <td>0.899323</td>\n",
       "      <td>0.257012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.865900</td>\n",
       "      <td>0.787196</td>\n",
       "      <td>0.257279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>0.610820</td>\n",
       "      <td>0.569856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.592700</td>\n",
       "      <td>0.546675</td>\n",
       "      <td>0.739689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.553300</td>\n",
       "      <td>0.528088</td>\n",
       "      <td>0.746311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.531800</td>\n",
       "      <td>0.496619</td>\n",
       "      <td>0.752567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.496300</td>\n",
       "      <td>0.498779</td>\n",
       "      <td>0.758920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.511800</td>\n",
       "      <td>0.475554</td>\n",
       "      <td>0.731007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.469200</td>\n",
       "      <td>0.477034</td>\n",
       "      <td>0.703705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.463100</td>\n",
       "      <td>0.456184</td>\n",
       "      <td>0.784807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>0.465399</td>\n",
       "      <td>0.772223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.489400</td>\n",
       "      <td>0.470263</td>\n",
       "      <td>0.780457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.433800</td>\n",
       "      <td>0.447131</td>\n",
       "      <td>0.779847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.446300</td>\n",
       "      <td>0.425729</td>\n",
       "      <td>0.786856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.446775</td>\n",
       "      <td>0.770900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.454800</td>\n",
       "      <td>0.430142</td>\n",
       "      <td>0.780263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.433400</td>\n",
       "      <td>0.426325</td>\n",
       "      <td>0.776496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>0.427647</td>\n",
       "      <td>0.778314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.433243</td>\n",
       "      <td>0.777185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.449800</td>\n",
       "      <td>0.427958</td>\n",
       "      <td>0.782302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.418000</td>\n",
       "      <td>0.425002</td>\n",
       "      <td>0.777798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.436886</td>\n",
       "      <td>0.785534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.431228</td>\n",
       "      <td>0.781017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 942\n",
      "  Batch size = 48\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e77579e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /notebooks/cascade_bert/saved_models/best-model-for-probs\n",
      "Configuration saved in /notebooks/cascade_bert/saved_models/best-model-for-probs/config.json\n",
      "Model weights saved in /notebooks/cascade_bert/saved_models/best-model-for-probs/pytorch_model.bin\n",
      "tokenizer config file saved in /notebooks/cascade_bert/saved_models/best-model-for-probs/tokenizer_config.json\n",
      "Special tokens file saved in /notebooks/cascade_bert/saved_models/best-model-for-probs/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "#save best model\n",
    "trainer.save_model(os.path.join(\"/notebooks/cascade_bert/saved_models\", 'best-model-for-probs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9395c94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f35781ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: feature_tensor, topic_full_sentence_structural_fts_combined, topic_full_sentence_stuctural_fts, sentence, text, split, topic_and_full_sentence.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1258\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='158' max='158' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [158/158 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_trainer = Trainer(model, data_collator=DataCollatorWithPadding(tokenizer))\n",
    "test_raw_preds, test_labels, _ = test_trainer.predict(test_dataset)\n",
    "test_preds = np.argmax(test_raw_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32973a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1b76772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Premise       0.93      0.89      0.91       805\n",
      "       Claim       0.69      0.67      0.68       301\n",
      "  MajorClaim       0.77      0.95      0.85       152\n",
      "\n",
      "    accuracy                           0.85      1258\n",
      "   macro avg       0.80      0.84      0.81      1258\n",
      "weighted avg       0.85      0.85      0.85      1258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_name = labels.int2str([0,1,2])\n",
    "print(classification_report(test_labels, test_preds, target_names=target_name))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95fef2e7",
   "metadata": {},
   "source": [
    "Results 1:\n",
    "    \n",
    "precision    recall  f1-score   support\n",
    "\n",
    "     Premise       0.80      0.82      0.81       805\n",
    "       Claim       0.43      0.40      0.41       301\n",
    "  MajorClaim       0.49      0.49      0.49       152\n",
    "\n",
    "    accuracy                           0.68      1258\n",
    "   macro avg       0.57      0.57      0.57      1258\n",
    "weighted avg       0.67      0.68      0.67      1258\n",
    "\n",
    "column = text, batch_size = 48, epoch = 6, learning_rate = 1e-5, "
   ]
  },
  {
   "cell_type": "raw",
   "id": "afae56e0",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim       0.46      0.49      0.48       301\n",
    "     Premise       0.85      0.80      0.82       805\n",
    "  MajorClaim       0.63      0.76      0.69       152\n",
    "\n",
    "    accuracy                           0.72      1258\n",
    "   macro avg       0.65      0.68      0.66      1258\n",
    "weighted avg       0.73      0.72      0.72      1258\n",
    "\n",
    "column = sentence, batch_size = 48, epoch = 6, learning_rate = 1e-5, "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d9b76bf",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim       0.45      0.48      0.46       301\n",
    "     Premise       0.84      0.81      0.83       805\n",
    "  MajorClaim       0.65      0.71      0.68       152\n",
    "\n",
    "    accuracy                           0.72      1258\n",
    "   macro avg       0.65      0.67      0.66      1258\n",
    "weighted avg       0.73      0.72      0.72      1258\n",
    "\n",
    "column = sentence, batch_size = 48, epoch = 6, learning_rate = 2e-5, "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d882fa4",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim       0.50      0.50      0.50       301\n",
    "  MajorClaim       0.66      0.74      0.70       152\n",
    "     Premise       0.85      0.83      0.84       805\n",
    "\n",
    "    accuracy                           0.74      1258\n",
    "   macro avg       0.67      0.69      0.68      1258\n",
    "weighted avg       0.75      0.74      0.74      1258\n",
    "\n",
    "column = topic and sentence, batch_size = 48, epoch = 6, learning_rate = 1e-5, "
   ]
  },
  {
   "cell_type": "raw",
   "id": "07f82d9b",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "  MajorClaim       0.80      0.93      0.86       152\n",
    "     Premise       0.92      0.90      0.91       805\n",
    "       Claim       0.69      0.67      0.68       301\n",
    "\n",
    "    accuracy                           0.85      1258\n",
    "   macro avg       0.80      0.83      0.81      1258\n",
    "weighted avg       0.85      0.85      0.85      1258\n",
    "\n",
    "column = topic_full_sentence_stuctural_fts, batch_size = 48, epoch = 6, learning_rate = 1e-5, "
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcc9d38d",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "     Premise       0.92      0.89      0.91       805\n",
    "       Claim       0.69      0.67      0.68       301\n",
    "  MajorClaim       0.79      0.95      0.87       152\n",
    "\n",
    "    accuracy                           0.85      1258\n",
    "   macro avg       0.80      0.84      0.82      1258\n",
    "weighted avg       0.85      0.85      0.85      1258\n",
    "\n",
    "column = topic_full_sentence_structural_fts_combined, batch_size = 48, epoch = 6, learning_rate = 1e-5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
